{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e67ddb7-7697-49ba-9deb-93e6bab25cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bilal\n",
      "> train=7,200, test=2,000, val=800\n",
      "yelp\n",
      "> train=47,146, test=5,894, val=5,893\n",
      "bilal - train\n",
      "> encoding ... finished!\n",
      "bilal - val\n",
      "> encoding ... finished!\n",
      "bilal - test\n",
      "> encoding ... finished!\n",
      "yelp - train\n",
      "> encoding ... finished!\n",
      "yelp - val\n",
      "> encoding ... finished!\n",
      "yelp - test\n",
      "> encoding ... finished!\n"
     ]
    }
   ],
   "source": [
    "# Test saving and loading models and then training them further:\n",
    "\n",
    "import datetime\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from tensorflow import keras\n",
    "    import tensorflow as tf\n",
    "    from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "\n",
    "from utils import local_save_dir\n",
    "\n",
    "\n",
    "EVAL_DIR = os.path.join(os.getcwd(), \"data\", \"transfer_learning_evaluation\")\n",
    "if not os.path.exists(EVAL_DIR):\n",
    "    os.mkdir(EVAL_DIR)\n",
    "ENCODING_DIR = os.path.join(os.path.dirname(os.getcwd()), \"encodings\")\n",
    "MODEL_DIR = os.path.join(os.path.dirname(os.getcwd()), \"models\")\n",
    "\n",
    "\n",
    "def get_google_drive_download_url(raw_url: str):\n",
    "    return \"https://drive.google.com/uc?id=\" + raw_url.split(\"/\")[-2]\n",
    "\n",
    "\n",
    "def shuffle(df: pd.DataFrame):\n",
    "    \"Make sure data is shuffled (deterministically).\"\n",
    "    ix = list(df.index)\n",
    "    random.seed(42)\n",
    "    random.shuffle(ix)\n",
    "    return df.loc[ix].reset_index(drop=True)\n",
    "\n",
    "\n",
    "def base_model():\n",
    "    \"\"\"Create a BERT model with parameters specified in the Bilal paper:\n",
    "    https://link.springer.com/article/10.1007/s10660-022-09560-w/tables/2\n",
    "\n",
    "        - model: TFBertForSequenceClassification\n",
    "        - learning rate: 2e-5\n",
    "        - epsilon: 1e-8\n",
    "    \"\"\"\n",
    "    # Using the TFBertForSequenceClassification as specified in the paper:\n",
    "    bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "    # Don't freeze any layers:\n",
    "    untrainable = []\n",
    "    trainable = [w.name for w in bert_model.weights]\n",
    "\n",
    "    for w in bert_model.weights:\n",
    "        if w.name in untrainable:\n",
    "            w._trainable = False\n",
    "        elif w.name in trainable:\n",
    "            w._trainable = True\n",
    "\n",
    "    # Compile the model:\n",
    "    bert_model.compile(\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5,epsilon=1e-08),\n",
    "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "        metrics = [tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")]\n",
    "    )\n",
    "\n",
    "    return bert_model\n",
    "\n",
    "\n",
    "datasets = dict()\n",
    "\n",
    "print(\"bilal\")\n",
    "\n",
    "datasets[\"bilal\"] = dict()\n",
    "\n",
    "bilal_train_url = \"https://drive.google.com/file/d/1i54O_JSAVtvP5ivor-ARJRkwSoBFdit1/view?usp=sharing\"\n",
    "bilal_test_url = \"https://drive.google.com/file/d/1boRdmasHB6JZDNBrlt6MRB1pUVnxxY-6/view?usp=sharing\"\n",
    "\n",
    "bilal_train_val = pd.read_csv(get_google_drive_download_url(bilal_train_url), encoding=\"latin1\")\n",
    "bilal_test = pd.read_csv(get_google_drive_download_url(bilal_test_url), encoding=\"latin1\")\n",
    "# Split train into 90-10 split for train-validation as per the paper:\n",
    "bilal_train, bilal_val = train_test_split(bilal_train_val, test_size=0.1, random_state=42)\n",
    "\n",
    "datasets[\"bilal\"][\"train\"] = bilal_train\n",
    "datasets[\"bilal\"][\"test\"] = bilal_test\n",
    "datasets[\"bilal\"][\"val\"] = bilal_val\n",
    "\n",
    "datasets[\"bilal\"][\"x_col\"] = \"sentence\"\n",
    "datasets[\"bilal\"][\"y_col\"] = \"label\"\n",
    "\n",
    "print(f\"> train={len(bilal_train):,}, test={len(bilal_test):,}, val={len(bilal_val):,}\")\n",
    "\n",
    "\n",
    "print(\"yelp\")\n",
    "\n",
    "datasets[\"yelp\"] = dict()\n",
    "\n",
    "yelp_train_url = \"https://drive.google.com/file/d/104W3CqRu4hUK1ht7wPfi8r8fDT7xdFCf/view?usp=sharing\"\n",
    "yelp_valid_url = \"https://drive.google.com/file/d/1--NRor8D2x5au59_B0LCk9wOHIc8Qh46/view?usp=sharing\"\n",
    "yelp_test_url = \"https://drive.google.com/file/d/1-3Czl0HdsMiVnnTQ4ckoAL0mcEDZGpsP/view?usp=sharing\"\n",
    "\n",
    "yelp_train = pd.read_csv(get_google_drive_download_url(yelp_train_url), encoding=\"utf-8\")\n",
    "yelp_val = pd.read_csv(get_google_drive_download_url(yelp_valid_url), encoding=\"utf-8\")\n",
    "yelp_test = pd.read_csv(get_google_drive_download_url(yelp_test_url), encoding=\"utf-8\")\n",
    "\n",
    "datasets[\"yelp\"][\"train\"] = yelp_train\n",
    "datasets[\"yelp\"][\"test\"] = yelp_test\n",
    "datasets[\"yelp\"][\"val\"] = yelp_val\n",
    "\n",
    "datasets[\"yelp\"][\"x_col\"] = \"text\"\n",
    "datasets[\"yelp\"][\"y_col\"] = \"label\"\n",
    "\n",
    "print(f\"> train={len(yelp_train):,}, test={len(yelp_test):,}, val={len(yelp_val):,}\")\n",
    "\n",
    "\n",
    "# Make all the encodings:\n",
    "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize(df: pd.DataFrame, x_col: str):\n",
    "    encodings = bert_tokenizer(\n",
    "        list(df[x_col].iloc[:100].values),  # Only 100 samples for testing.\n",
    "        max_length=320,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\", \n",
    "        return_tensors=\"tf\"\n",
    "    )\n",
    "    return encodings\n",
    "\n",
    "\n",
    "# Make the encodings and save them if not already done:\n",
    "for name, values in datasets.items():\n",
    "    dir_path = os.path.join(ENCODING_DIR, f\"TEST_{name}\")\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.mkdir(dir_path)\n",
    "    for key in (\"train\", \"val\", \"test\"):\n",
    "        print(f\"{name} - {key}\")\n",
    "        fp = os.path.join(dir_path, f\"{key}_tokenized.obj\")\n",
    "        if not os.path.exists(fp):\n",
    "            print(f\"> encoding ... \", end=\"\")\n",
    "            x_col = values[\"x_col\"]\n",
    "            encodings = tokenize(values[key], x_col)\n",
    "            with open(fp, \"wb\") as f:\n",
    "                pickle.dump(encodings, f)\n",
    "            print(\"finished!\")\n",
    "        else:\n",
    "            print(\"> already encoded!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "212c5f16-0276-4bf8-be6b-e5f97b54ce7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = base_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b98967f0-8a00-46c9-a5c6-58aa0eb5746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load encodings:\n",
    "\n",
    "for name, values in datasets.items():\n",
    "    dir_path = os.path.join(ENCODING_DIR, f\"TEST_{name}\")\n",
    "    for key in (\"train\", \"val\", \"test\"):\n",
    "        encodings_name = f\"{key}_tokenized\" \n",
    "        fp = os.path.join(dir_path, f\"{encodings_name}.obj\")\n",
    "        if not os.path.exists(fp):\n",
    "            print(f\"File not found (run make_encodings.py first):\\n  {fp}\")\n",
    "        else:\n",
    "            with open(fp, \"rb\") as f:\n",
    "                encodings = pickle.load(f)\n",
    "                datasets[name][f\"{key}_tokenized\"] = encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93080954-b3ca-4343-bb6c-e02a32a4663c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: /home/tp/models/TEST/checkpoints/2022_07_23__03_35_51\n",
      "Epoch 1/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.6000\n",
      "Epoch 1: saving model to /home/tp/models/TEST/checkpoints/2022_07_23__03_35_51/cp-0001.ckpt\n",
      "7/7 [==============================] - 32s 2s/step - loss: 0.6716 - accuracy: 0.6000 - val_loss: 0.6874 - val_accuracy: 0.6300\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5475 - accuracy: 0.7500\n",
      "Epoch 2: saving model to /home/tp/models/TEST/checkpoints/2022_07_23__03_35_51/cp-0002.ckpt\n",
      "7/7 [==============================] - 13s 2s/step - loss: 0.5475 - accuracy: 0.7500 - val_loss: 0.6026 - val_accuracy: 0.7100\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4984 - accuracy: 0.8000\n",
      "Epoch 3: saving model to /home/tp/models/TEST/checkpoints/2022_07_23__03_35_51/cp-0003.ckpt\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.4984 - accuracy: 0.8000 - val_loss: 0.7203 - val_accuracy: 0.6000\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.8000\n",
      "Epoch 4: saving model to /home/tp/models/TEST/checkpoints/2022_07_23__03_35_51/cp-0004.ckpt\n",
      "7/7 [==============================] - 14s 2s/step - loss: 0.4750 - accuracy: 0.8000 - val_loss: 0.6183 - val_accuracy: 0.7100\n"
     ]
    }
   ],
   "source": [
    "# Train model:\n",
    "# Create directory for storing checkpoints after each epoch:\n",
    "checkpoint_dir = local_save_dir(\"checkpoints\", model_name = \"TEST\")\n",
    "checkpoint_path = checkpoint_dir + \"/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights:\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "train_encodings = datasets[\"bilal\"][\"train_tokenized\"]\n",
    "y_train = datasets[\"bilal\"][\"train\"][\"label\"].iloc[:100]\n",
    "valid_encodings = datasets[\"bilal\"][\"val_tokenized\"]\n",
    "y_val = datasets[\"bilal\"][\"val\"][\"label\"].iloc[:100]\n",
    "\n",
    "# Fit the model saving weights every epoch:\n",
    "history = model.fit(\n",
    "    [train_encodings.input_ids, train_encodings.token_type_ids, train_encodings.attention_mask],\n",
    "    y_train.values,\n",
    "    validation_data=(\n",
    "        [valid_encodings.input_ids, valid_encodings.token_type_ids, valid_encodings.attention_mask],\n",
    "        y_val.values\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    epochs=4,\n",
    "    callbacks=[cp_callback]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f2f7571-3155-409f-82bb-6db742d9abd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: /home/tp/models/TEST/full_model_weights/2022_07_23__03_51_47\n"
     ]
    }
   ],
   "source": [
    "model_dir = local_save_dir(\"full_model_weights\", model_name = \"TEST\")\n",
    "model.save_weights(f\"{model_dir}/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f28d7aae-17a4-48b3-b417-e08c266b85c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_weights_path = \"/home/tp/models/TEST/full_model_weights/2022_07_23__03_51_47\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ffc48670-5df2-4dfe-a897-0b4eeece1cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model now has 2 trainable layers, 199 untrainable.\n"
     ]
    }
   ],
   "source": [
    "def freeze_except_classifier(model):\n",
    "    \"\"\"Make all layers untrainable except the final classifier layers.\"\"\"\n",
    "    trainable, untrainable = 0, 0\n",
    "    for w in model.weights:\n",
    "        if w.name.split(\"/\")[1] == \"classifier\":\n",
    "            w._trainable = True\n",
    "            trainable += 1\n",
    "        else:\n",
    "            w._trainable = False\n",
    "            untrainable += 1\n",
    "    print(f\"Model now has {trainable} trainable layers, {untrainable} untrainable.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "loaded_model = base_model()\n",
    "loaded_model.load_weights(f\"{model_dir}/pretrained_weights.h5\")\n",
    "# loaded_model = keras.models.load_model(model_path)\n",
    "loaded_model = freeze_except_classifier(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01650b90-128a-4e8b-ab13-cc920e748b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = datasets[\"yelp\"][\"train_tokenized\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "017cdc5d-eaae-41e5-bcd7-42b4e9cc3097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dir: /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/checkpoints/2022_07_23__03_54_05\n",
      "Epoch 1/4\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_for_sequence_classification_5/bert/embeddings/word_embeddings/weight:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/token_type_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/position_embeddings/embeddings:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/embeddings/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._0/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._1/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._2/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._3/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._4/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._5/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._6/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._7/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._8/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._9/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._10/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/query/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/key/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/self/value/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/attention/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/intermediate/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/dense/bias:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/gamma:0', 'tf_bert_for_sequence_classification_5/bert/encoder/layer_._11/output/LayerNorm/beta:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/kernel:0', 'tf_bert_for_sequence_classification_5/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - ETA: 0s - loss: 0.5675 - accuracy: 0.7200\n",
      "Epoch 1: saving model to /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/checkpoints/2022_07_23__03_54_05/cp-0001.ckpt\n",
      "7/7 [==============================] - 13s 1s/step - loss: 0.5675 - accuracy: 0.7200 - val_loss: 0.7212 - val_accuracy: 0.5600\n",
      "Epoch 2/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5478 - accuracy: 0.7400\n",
      "Epoch 2: saving model to /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/checkpoints/2022_07_23__03_54_05/cp-0002.ckpt\n",
      "7/7 [==============================] - 5s 828ms/step - loss: 0.5478 - accuracy: 0.7400 - val_loss: 0.7217 - val_accuracy: 0.5800\n",
      "Epoch 3/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.7600\n",
      "Epoch 3: saving model to /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/checkpoints/2022_07_23__03_54_05/cp-0003.ckpt\n",
      "7/7 [==============================] - 6s 876ms/step - loss: 0.5365 - accuracy: 0.7600 - val_loss: 0.7229 - val_accuracy: 0.5800\n",
      "Epoch 4/4\n",
      "7/7 [==============================] - ETA: 0s - loss: 0.5351 - accuracy: 0.7300\n",
      "Epoch 4: saving model to /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/checkpoints/2022_07_23__03_54_05/cp-0004.ckpt\n",
      "7/7 [==============================] - 5s 845ms/step - loss: 0.5351 - accuracy: 0.7300 - val_loss: 0.7263 - val_accuracy: 0.5700\n",
      "Saving model ...\n",
      "Created dir: /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/full_model/2022_07_23__03_54_34\n",
      "Saving history ...\n",
      "Created dir: /home/tp/models/TEST_CLASSIFIER_FINETUNED_ON_yelp/history/2022_07_23__03_54_35\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"yelp\"\n",
    "\n",
    "finetune_name = f\"TEST_CLASSIFIER_FINETUNED_ON_yelp\"\n",
    "\n",
    "# Create directory for storing checkpoints after each epoch:\n",
    "checkpoint_dir = local_save_dir(\"checkpoints\", model_name = finetune_name)\n",
    "checkpoint_path = checkpoint_dir + \"/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights:\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=1)\n",
    "\n",
    "y_col = datasets[dataset_name][\"y_col\"]\n",
    "y_train = datasets[dataset_name][\"train\"][y_col].iloc[:100]\n",
    "y_val = datasets[dataset_name][\"val\"][y_col].iloc[:100]\n",
    "\n",
    "# Fit the model saving weights every epoch:\n",
    "history = loaded_model.fit(\n",
    "    [train_encodings.input_ids, train_encodings.token_type_ids, train_encodings.attention_mask],\n",
    "    y_train.values,\n",
    "    validation_data=(\n",
    "        [valid_encodings.input_ids, valid_encodings.token_type_ids, valid_encodings.attention_mask],\n",
    "        y_val.values\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    epochs=4,\n",
    "    callbacks=[cp_callback]\n",
    ")\n",
    "\n",
    "print(\"Saving model ...\")\n",
    "model_dir = local_save_dir(\"full_model\", model_name = finetune_name)\n",
    "loaded_model.save_weights(\"pretrained_weights.h5\")\n",
    "\n",
    "\n",
    "print(\"Saving history ...\")\n",
    "hist_dir = local_save_dir(\"history\", model_name = finetune_name)\n",
    "with open(os.path.join(hist_dir, \"hist_dict\"), \"wb\") as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "print(\"Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc3d75c-464b-47ed-942d-24b387ca63ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
